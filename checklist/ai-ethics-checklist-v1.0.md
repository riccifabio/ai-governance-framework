# AI Ethics Checklist — v1.0

# AI Ethics & Governance Checklist — v1.0

Status: usable, evolving

This checklist is designed to support **decision-making** around AI systems.
It does not provide definitive answers, but structures responsibility,
trade-offs, and accountability.

Use it as a discussion tool, not as a scoring or certification mechanism.

---

## 1. Decision Context & Purpose

1. Is the **decision that the AI system supports or automates clearly defined**?
2. Is the **intended purpose** of the system explicit and documented?
3. Is there a risk of **function creep** (use beyond the original purpose)?
4. Would the decision still be acceptable **without AI**, or is AI compensating for organizational weaknesses?

---

## 2. Human Impact & Affected Stakeholders

5. Who is **directly affected** by the system’s outputs or decisions?
6. Who is **indirectly affected**, even if not immediately visible?
7. Are vulnerable groups potentially impacted?
8. Can affected individuals **understand that AI is involved** in the decision?

---

## 3. Degree of Automation & Human Control

9. What level of automation is in place (support, recommendation, decision)?
10. Is there a **meaningful human-in-the-loop** or human-on-the-loop?
11. Can a human **override or stop** the system?
12. Is human intervention realistic in practice, not just on paper?

---

## 4. Transparency & Explainability

13. Can the system’s behavior be **explained at an appropriate level** to different stakeholders?
14. Are explanations available **before, during, or after** a decision?
15. Is there a gap between what developers understand and what decision-makers understand?
16. Would a reasonable person accept the decision **if it were explained to them**?

---

## 5. Responsibility & Accountability

17. Who is **accountable** for the outcomes produced with the AI system?
18. Is responsibility clearly assigned, or implicitly shifted to “the system”?
19. Are escalation paths defined when something goes wrong?
20. Is accountability preserved even when third-party vendors are involved?

---

## 6. Data & Bias Awareness

21. Is the origin of training and input data known and documented?
22. Are there known biases or data limitations relevant to the context?
23. Has the system been tested for **uneven impact** across groups?
24. Are mitigation strategies in place, or are risks merely acknowledged?

---

## 7. Risk, Harm & Proportionality

25. What is the **worst plausible harm** this system could cause?
26. How reversible are the system’s decisions?
27. Is the level of automation **proportionate to the risk** involved?
28. Are safeguards aligned with the severity of potential harm?

---

## 8. Right to Challenge & Dissent

29. Can affected individuals **challenge or contest** decisions?
30. Is there a clear process to request review or explanation?
31. Are dissenting opinions allowed internally during deployment decisions?
32. Is disagreement treated as a governance signal, not as resistance?

---

## 9. Monitoring & Evolution

33. Is the system’s performance monitored over time?
34. Are ethical or social risks reviewed periodically, not only at launch?
35. Is there a process to update, limit, or retire the system?
36. Are past decisions revisited when context or impact changes?

---

## Final Reflection (Do not skip)

37. If this decision were made public tomorrow, could it be **reasonably defended**?
38. Are we accepting this decision because it is right, or because it is convenient?
39. Are we still in control of the system, or is the system shaping our choices?
40. Would we make the same decision again, knowing what we know now?

---

## How to Use This Checklist

- Apply it **before deployment**, during procurement, or when revisiting existing systems.
- Focus on **discussion and documentation**, not on yes/no answers.
- Record disagreements and unresolved tensions.
- Treat the checklist as a living tool that evolves with practice.

