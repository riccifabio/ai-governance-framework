# AI Ethics & Governance Checklist — v1.0

Status: usable, evolving

This checklist is a **decision-support tool** for AI-related initiatives.
It structures responsibility, trade-offs, and accountability.
It does not certify ethical compliance and does not replace human judgment.

---

## How to Use This Checklist

Use this checklist when:
- evaluating or procuring AI systems
- introducing automation in sensitive contexts
- revisiting existing AI deployments
- accountability and responsibility are unclear

### How to apply it

1. Apply the questions **before deployment or major changes**.
2. Answer collaboratively across roles (business, tech, legal, HR).
3. Focus on **discussion and documentation**, not on yes/no answers.
4. Record disagreements and unresolved tensions.
5. Revisit the checklist over time as context and impact evolve.

---

## Scoring & Metrics (Optional but Recommended)

### Purpose of the Score

The score exists to:
- assess **decision readiness**
- highlight governance gaps
- justify delay, redesign, or limitation of automation
- support escalation and accountability

The score must **not** be used to:
- certify systems as “ethical”
- produce marketing claims
- replace human responsibility

---

### Scoring Model — Decision Readiness

Each checklist section (1–9) is scored independently.

For each question, assign:

- **0 — Not addressed**
- **1 — Acknowledged but unmanaged**
- **2 — Partially managed**
- **3 — Explicitly managed and documented**

---

### Interpreting Section Scores

Each section contains 4 questions (maximum score: 12).

- **0–4 → Low readiness**  
  Governance gaps are significant. Automation should be stopped or constrained.

- **5–8 → Medium readiness**  
  Risks are partially managed. Proceed only with safeguards and monitoring.

- **9–12 → High readiness**  
  Decision context is well governed. Automation may be acceptable.

> Scores are **signals**, not approvals.

---

### No Global Score Rule

This framework intentionally **does not produce a single total score**.

A single low-readiness section (e.g. accountability or right to challenge)
is sufficient to block or limit deployment, regardless of other high scores.

Governance decisions remain **contextual and accountable**.

---

## Checklist Questions

### 1. Decision Context & Purpose

1. Is the decision that the AI system supports or automates clearly defined?
2. Is the intended purpose of the system explicit and documented?
3. Is there a risk of function creep (use beyond the original purpose)?
4. Would the decision still be acceptable without AI, or is AI compensating for organizational weaknesses?

---

### 2. Human Impact & Affected Stakeholders

5. Who is directly affected by the system’s outputs or decisions?
6. Who is indirectly affected, even if not immediately visible?
7. Are vulnerable groups potentially impacted?
8. Can affected individuals understand that AI is involved in the decision?

---

### 3. Degree of Automation & Human Control

9. What level of automation is in place (support, recommendation, decision)?
10. Is there a meaningful human-in-the-loop or human-on-the-loop?
11. Can a human override or stop the system?
12. Is human intervention realistic in practice, not just on paper?

---

### 4. Transparency & Explainability

13. Can the system’s behavior be explained at an appropriate level to different stakeholders?
14. Are explanations available before, during, or after a decision?
15. Is there a gap between what developers understand and what decision-makers understand?
16. Would a reasonable person accept the decision if it were explained to them?

---

### 5. Responsibility & Accountability

17. Who is accountable for the outcomes produced with the AI system?
18. Is responsibility clearly assigned, or implicitly shifted to “the system”?
19. Are escalation paths defined when something goes wrong?
20. Is accountability preserved even when third-party vendors are involved?

---

### 6. Data & Bias Awareness

21. Is the origin of training and input data known and documented?
22. Are there known biases or data limitations relevant to the context?
23. Has the system been tested for uneven impact across groups?
24. Are mitigation strategies in place, or are risks merely acknowledged?

---

### 7. Risk, Harm & Proportionality

25. What is the worst plausible harm this system could cause?
26. How reversible are the system’s decisions?
27. Is the level of automation proportionate to the risk involved?
28. Are safeguards aligned with the severity of potential harm?

---

### 8. Right to Challenge & Dissent

29. Can affected individuals challenge or contest decisions?
30. Is there a clear process to request review or explanation?
31. Are dissenting opinions allowed internally during deployment decisions?
32. Is disagreement treated as a governance signal, not as resistance?

---

### 9. Monitoring & Evolution

33. Is the system’s performance monitored over time?
34. Are ethical or social risks reviewed periodically, not only at launch?
35. Is there a process to update, limit, or retire the system?
36. Are past decisions revisited when context or impact changes?

---

## Final Reflection (Do Not Skip)

37. If this decision were made public tomorrow, could it be reasonably defended?
38. Are we accepting this decision because it is right, or because it is convenient?
39. Are we still in control of the system, or is the system shaping our choices?
40. Would we make the same decision again, knowing what we know now?

---

End of checklist.


