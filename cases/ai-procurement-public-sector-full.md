## Decision Readiness Scoring (Detailed)

Scoring applied according to the Decision Readiness model.
Scores reflect **governance readiness of the decision**, not ethical quality of the AI system.

---

### 1. Decision Context & Purpose (Score: 7 / 12 — Medium readiness)

1. Decision clearly defined → 2  
2. Intended purpose explicit and documented → 2  
3. Function creep risk addressed → 1  
4. Acceptable without AI → 2  

**Comment:**  
The operational goal is clear, but boundaries of acceptable use are weak.
High risk of reuse beyond the original scope is insufficiently governed.

---

### 2. Human Impact & Affected Stakeholders (Score: 4 / 12 — Low readiness)

5. Directly affected stakeholders identified → 1  
6. Indirect stakeholders identified → 1  
7. Vulnerable groups considered → 1  
8. Awareness of AI involvement → 1  

**Comment:**  
Impact on citizens is acknowledged abstractly.
No concrete mechanisms exist to inform or protect vulnerable populations.

---

### 3. Degree of Automation & Human Control (Score: 4 / 12 — Low readiness)

9. Level of automation defined → 2  
10. Meaningful human-in-the-loop → 1  
11. Override capability → 1  
12. Realistic human intervention → 0  

**Comment:**  
Although framed as decision support, operational pressure turns
recommendations into de facto decisions.

---

### 4. Transparency & Explainability (Score: 3 / 12 — Low readiness)

13. Appropriate explanations available → 1  
14. Timing of explanations defined → 1  
15. Gap between technical and decision understanding → 0  
16. Reasonable person test satisfied → 1  

**Comment:**  
Explanations are internally oriented and unsuitable for citizens.
Procurement decisions rely on vendor documentation without scrutiny.

---

### 5. Responsibility & Accountability (Score: 3 / 12 — Low readiness)

17. Accountable role clearly assigned → 1  
18. Responsibility shifted to system/vendor → 0  
19. Escalation paths defined → 1  
20. Third-party accountability preserved → 1  

**Comment:**  
Accountability is diffused across departments.
Vendor responsibility is assumed rather than contractually enforced.

---

### 6. Data & Bias Awareness (Score: 2 / 12 — Low readiness)

21. Data origin documented → 1  
22. Biases and limitations known → 1  
23. Uneven impact testing performed → 0  
24. Mitigation strategies in place → 0  

**Comment:**  
Historical administrative data embeds structural bias.
No validation or mitigation strategy is defined.

---

### 7. Risk, Harm & Proportionality (Score: 3 / 12 — Low readiness)

25. Worst plausible harm identified → 1  
26. Reversibility of decisions → 0  
27. Proportionality of automation → 1  
28. Safeguards aligned with severity → 1  

**Comment:**  
Potential harm to citizens is significant and partially irreversible.
Safeguards are not proportionate to the impact on rights.

---

### 8. Right to Challenge & Dissent (Score: 2 / 12 — Low readiness)

29. External challenge mechanisms → 0  
30. Review or explanation process → 0  
31. Internal dissent allowed → 1  
32. Dissent treated as governance signal → 1  

**Comment:**  
Neither citizens nor caseworkers have formal avenues to challenge outcomes.
Efficiency pressure discourages dissent.

---

### 9. Monitoring & Evolution (Score: 2 / 12 — Low readiness)

33. Ongoing performance monitoring → 1  
34. Periodic ethical or social review → 0  
35. System update or retirement process → 1  
36. Decision revisited over time → 0  

**Comment:**  
Monitoring focuses exclusively on throughput.
No lifecycle governance is defined.

---

## Scoring Summary

| Section | Score | Readiness |
|------|-------|-----------|
| Decision Context & Purpose | 7 / 12 | Medium |
| Human Impact | 4 / 12 | Low |
| Automation & Control | 4 / 12 | Low |
| Transparency | 3 / 12 | Low |
| Accountability | 3 / 12 | Low |
| Data & Bias | 2 / 12 | Low |
| Risk & Proportionality | 3 / 12 | Low |
| Right to Challenge | 2 / 12 | Low |
| Monitoring & Evolution | 2 / 12 | Low |

---

## Governance Interpretation

Multiple **low-readiness sections** constitute **hard stop signals**
according to the framework rules.

The procurement decision is **not governance-ready** for deployment
in citizen-facing prioritization.

Limiting AI use to internal analytics and introducing governance
requirements into procurement criteria is consistent with the
identified readiness gaps.

---

## Governance Insight

The scoring did not evaluate the AI system itself.
It exposed a lack of **institutional readiness to delegate
rights-affecting prioritization to automation**.

This distinction was decisive in reframing the procurement outcome.
