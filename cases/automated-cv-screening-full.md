## Decision Readiness Scoring

Scoring applied according to the guidelines defined in the checklist.
Scores reflect **decision readiness**, not ethical value of the AI system.

---

### 1. Decision Context & Purpose (Score: 8 / 12 — Medium readiness)

1. Decision clearly defined → 3  
2. Purpose explicit and documented → 2  
3. Function creep risk addressed → 1  
4. Acceptable without AI → 2  

**Comment:**  
The decision scope is clear, but boundaries of acceptable use are weakly defined.
Function creep risk is acknowledged but not governed.

---

### 2. Human Impact & Affected Stakeholders (Score: 5 / 12 — Medium–Low readiness)

5. Directly affected stakeholders identified → 2  
6. Indirect stakeholders identified → 1  
7. Vulnerable groups considered → 1  
8. Awareness of AI involvement → 1  

**Comment:**  
Impact is partially understood, but candidate perspective is underrepresented.
Transparency toward applicants was initially absent.

---

### 3. Degree of Automation & Human Control (Score: 3 / 12 — Low readiness)

9. Level of automation defined → 1  
10. Meaningful human-in-the-loop → 0  
11. Override capability → 1  
12. Realistic human intervention → 1  

**Comment:**  
Automation design prioritizes efficiency over control.
Human oversight exists formally, but not operationally.

---

### 4. Transparency & Explainability (Score: 4 / 12 — Low readiness)

13. Appropriate explanations available → 1  
14. Timing of explanations defined → 1  
15. Gap between technical and decision understanding → 1  
16. Reasonable person test satisfied → 1  

**Comment:**  
Explanations are vendor-oriented and insufficient for candidates or recruiters.
Decision-makers rely heavily on external assurances.

---

### 5. Responsibility & Accountability (Score: 3 / 12 — Low readiness)

17. Accountable role clearly assigned → 1  
18. Responsibility shifted to system/vendor → 0  
19. Escalation paths defined → 1  
20. Third-party accountability preserved → 1  

**Comment:**  
Accountability is fragmented and implicitly externalized.
Governance roles are not formalized.

---

### 6. Data & Bias Awareness (Score: 3 / 12 — Low readiness)

21. Data origin documented → 1  
22. Biases and limitations known → 1  
23. Uneven impact testing performed → 0  
24. Mitigation strategies in place → 1  

**Comment:**  
Bias risk is acknowledged rhetorically, not operationally.
No independent validation or mitigation plan exists.

---

### 7. Risk, Harm & Proportionality (Score: 4 / 12 — Low readiness)

25. Worst plausible harm identified → 2  
26. Reversibility of decisions → 0  
27. Proportionality of automation → 1  
28. Safeguards aligned with severity → 1  

**Comment:**  
Potential harm is understood, but safeguards are insufficient.
Irreversibility of early exclusion is a critical weakness.

---

### 8. Right to Challenge & Dissent (Score: 2 / 12 — Low readiness)

29. External challenge mechanisms → 0  
30. Review or explanation process → 0  
31. Internal dissent allowed → 1  
32. Dissent treated as governance signal → 1  

**Comment:**  
Both external and internal challenge mechanisms are weak.
Disagreement is tolerated, not structurally integrated.

---

### 9. Monitoring & Evolution (Score: 3 / 12 — Low readiness)

33. Ongoing performance monitoring → 1  
34. Periodic ethical review → 0  
35. System update or retirement process → 1  
36. Decision revisited over time → 1  

**Comment:**  
Monitoring focuses on efficiency metrics.
No lifecycle governance is defined.

---

## Scoring Summary

| Section | Score | Readiness |
|------|-------|-----------|
| Decision Context | 8 / 12 | Medium |
| Human Impact | 5 / 12 | Medium–Low |
| Automation & Control | 3 / 12 | Low |
| Transparency | 4 / 12 | Low |
| Accountability | 3 / 12 | Low |
| Data & Bias | 3 / 12 | Low |
| Risk & Proportionality | 4 / 12 | Low |
| Right to Challenge | 2 / 12 | Low |
| Monitoring & Evolution | 3 / 12 | Low |

---

## Governance Interpretation

Despite moderate clarity on purpose, **multiple low-readiness sections**
(Accountability, Automation, Right to Challenge) constitute **hard stop signals**
according to the framework rules.

The scoring confirms that **full automation is not governance-ready**.

The final decision to deploy the system only as decision support
is consistent with the identified readiness gaps.

---

## Governance Insight

The score did not “fail” the AI system.
It revealed that the **organization was not ready to delegate exclusion decisions**
to automation without losing accountability.

This distinction was essential to reach a defensible outcome.
